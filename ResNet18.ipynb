{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###1. Use Resnet18 to train on CIFAR-10\t\n",
        "\n",
        "###2. Experiment on the following and compare the result with baseline\n",
        "* Input image normalization\n",
        "* Data augmentation\n",
        "* Different base learning rate and update strategy\n",
        "* Different batch size\n",
        "\n",
        "###3. Print test loss and test acc\n",
        "\n",
        "###4. Plot train-loss, val-loss, train-acc, val-acc\n",
        "\n",
        "###5. Accuracy(>90%拿滿，>80%才有基本分)"
      ],
      "metadata": {
        "id": "WK9v01wL7bhs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "uTY8C-LBhDTX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create SummaryWriter\n",
        "writer = SummaryWriter(\"../tensorboard\")"
      ],
      "metadata": {
        "id": "io7k6zHGb1OJ"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "oqc_D_uEhc1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20b62a0-fcc1-4ed7-e157-35bb1847b0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# 檢查是否可用gpu\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "CrsS13SChs9b"
      },
      "outputs": [],
      "source": [
        "# setting parameter\n",
        "EPOCH = 0     \n",
        "BATCH_SIZE = 128    \n",
        "lr = 0.05        \n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "3LzusjVfhxJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab59b691-2aa1-4949-b250-18a0000fb97a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff323ed4440>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff323ed4440>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    self._shutdown_workers()\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "\n",
            "AssertionErrorcan only test a child process: \n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff323ed4440>\n",
            "    Traceback (most recent call last):\n",
            "if w.is_alive():  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "\n",
            "      File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    \n",
            "if w.is_alive():\n",
            "      File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionErrorAssertionError: : can only test a child process\n",
            "Exception ignored in: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7ff323ed4440>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "Exception ignored in:     self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7ff323ed4440>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionError  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            ":     can only test a child processif w.is_alive():\n",
            "\n",
            "      File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff323ed4440>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.49157307 0.48275957 0.447229  ] [0.24722555 0.24367255 0.26229316]\n"
          ]
        }
      ],
      "source": [
        "# 計算normalization需要的mean & std\n",
        "def get_mean_std(dataset, ratio=0.3):\n",
        "    # Get mean and std by sample ratio\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=int(len(dataset)*ratio), shuffle=True, num_workers=2)\n",
        "\n",
        "    data = iter(dataloader).next()[0]     # get the first iteration data\n",
        "    mean = np.mean(data.numpy(), axis=(0,2,3))\n",
        "    std = np.std(data.numpy(), axis=(0,2,3))\n",
        "    return mean, std\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_mean, train_std = get_mean_std(train_dataset)\n",
        "\n",
        "print(train_mean, train_std)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算Gaussian noise\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "metadata": {
        "id": "LkcHJBCRpiwq"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(mean = (0.4901,0.4809,0.4445), std = (0.2460,0.2425,0.2607))\n",
        "\n",
        "# data augmentation & normalization\n",
        "transform_train = transforms.Compose([\n",
        "    # data augmentation\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    # data normalization    # standardization: (image - train_mean) / train_std\n",
        "    normalize,\n",
        "    AddGaussianNoise(0., 1.)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # data normalization    # standardization: (image - train_mean) / train_std\n",
        "    normalize,\n",
        "])"
      ],
      "metadata": {
        "id": "5NGnL4rP6ofO"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_ds = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# 檢查training dataset長怎麼樣 \n",
        "#print(trainset)\n",
        "#print(\"trainset length: \", len(trainset))\n",
        "#print(\"classes: \", trainset.classes)\n",
        "\n",
        "# Cifar-10的標籤: ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# split validation dataset\n",
        "torch.manual_seed(43)     # 確保每次獲得相同的驗證集\n",
        "val_size = 5000       # 取5000張驗證集(0.1 of trainset)\n",
        "train_size = len(trainset) - val_size\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "print(\"train length: \", len(train_ds))\n",
        "print(\"val length: \", len(val_ds))\n",
        "print(\"test length: \", len(test_ds))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   #生成batch \n",
        "valloader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "oaJyYUXj6rNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd5a194-1d18-4661-93a2-22ee38914140"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train length:  45000\n",
            "val length:  5000\n",
            "test length:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate shedule\n",
        "def adjust_learning_rate(optim, epoch):\n",
        "    # define your lr scheduler\n",
        "    if epoch == 20:\n",
        "        lr_t = optim.param_groups[0]['lr'] * 0.1\n",
        "    elif epoch == 40:\n",
        "        lr_t = optim.param_groups[0]['lr'] * 0.8\n",
        "    else:\n",
        "        lr_t = optim.param_groups[0]['lr']\n",
        "\n",
        "    for param_group in optim.param_groups:    # change the lr to what you define\n",
        "        param_group['lr'] = lr_t"
      ],
      "metadata": {
        "id": "EgJejgUOVviV"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#是否pretrain\n",
        "#net = models.resnet18(pretrained = False).to(device)\n",
        "net = models.resnet18(pretrained = False)\n",
        "net.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "net.fc = nn.Linear(512,10)\n",
        "net = net.to(device)\n",
        "print(net)\n",
        "if device == 'cuda':\n",
        "  net = torch.nn.DataParallel(net)\n",
        "\n",
        "# 定義損失函數和優化方式\n",
        "criterion = nn.CrossEntropyLoss()  #loss function \n",
        "#optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)   # momentum-SGD，採用L2正則化（權重衰減）\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "if __name__ == \"__main__\":\n",
        "    train_loss, train_acc = [], []\n",
        "    val_loss, val_acc = [], []\n",
        "    for epoch in range(50):\n",
        "        # train\n",
        "        net.train()\n",
        "        sum1_loss, sum2_loss = 0.0, 0.0\n",
        "        correct = 0.0\n",
        "        total = 0.0\n",
        "        print('\\nEpoch: %d' % (epoch + 1))\n",
        "        for i, traindata in enumerate(trainloader, 0):\n",
        "            # prepare data\n",
        "            inputs, train_labels = traindata\n",
        "            inputs, train_labels = inputs.to(device), train_labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward\n",
        "            train_outputs = net(inputs)\n",
        "            trainloss = criterion(train_outputs, train_labels)\n",
        "            trainloss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 每訓練1個batch的loss和acc\n",
        "            sum1_loss += trainloss.item()\n",
        "            _, predicted = torch.max(train_outputs.data, 1)     # 取得分數最高的那個類 (outputs.data的index)\n",
        "            total += train_labels.size(0)\n",
        "            correct += predicted.eq(train_labels.data).cpu().sum()\n",
        "\n",
        "        # learning rate schedule\n",
        "        #writer.add_scalar(\"lr\", optimizer.param_groups[0]['lr'], epoch)\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "        print(\"learning rate: \",  optimizer.param_groups[0]['lr'])\n",
        "        \n",
        "        loss1 = sum1_loss / (i + 1)\n",
        "        acc1 = correct / total\n",
        "        print(\"Train loss: %.3f | Train acc: %.3f\" % (loss1, acc1))\n",
        "        train_loss.append(loss1)\n",
        "        train_acc.append(acc1.item())\n",
        "\n",
        "        # 用val驗證\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for j, valdata in enumerate(valloader, 0):\n",
        "                net.eval()\n",
        "                images, val_labels = valdata\n",
        "                images, val_labels = images.to(device), val_labels.to(device)\n",
        "                val_outputs = net(images)\n",
        "                valloss = criterion(val_outputs, val_labels)\n",
        "                        \n",
        "                sum2_loss += valloss.item()\n",
        "                _, predicted = torch.max(val_outputs.data, 1)\n",
        "                total += val_labels.size(0)\n",
        "                correct += (predicted == val_labels).sum()\n",
        "                    \n",
        "            loss2 = sum2_loss / (j + 1)\n",
        "            acc2 = correct / total\n",
        "            print(\"Val loss: %.3f | Val acc: %.3f\" % (loss2, acc2))\n",
        "            val_loss.append(loss2)\n",
        "            val_acc.append(acc2.item())\n",
        "\n",
        "    # 用test測試\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        sum3_loss = 0.0\n",
        "        for k, testdata in enumerate(testloader, 0):\n",
        "            net.eval()\n",
        "            imgs, test_labels = testdata\n",
        "            imgs, test_labels = imgs.to(device), test_labels.to(device)\n",
        "            test_outputs = net(imgs)\n",
        "            testloss = criterion(test_outputs, test_labels)\n",
        "                        \n",
        "            sum3_loss += testloss.item()\n",
        "            _, predicted = torch.max(test_outputs.data, 1)\n",
        "            total += test_labels.size(0)\n",
        "            correct += (predicted == test_labels).sum()\n",
        "                    \n",
        "        loss3 = sum3_loss / (k + 1)\n",
        "        acc3 = correct / total\n",
        "        print(\"Test loss: %.3f | Test acc: %.3f\" % (loss3, acc3))"
      ],
      "metadata": {
        "id": "WfBB9RKK6t8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16150822-34b5-4f85-fc60-95aab0edd6cd"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "Epoch: 1\n",
            "learning rate:  0.05\n",
            "Train loss: 1.782 | Train acc: 0.360\n",
            "Val loss: 1.631 | Val acc: 0.394\n",
            "\n",
            "Epoch: 2\n",
            "learning rate:  0.05\n",
            "Train loss: 1.437 | Train acc: 0.479\n",
            "Val loss: 1.518 | Val acc: 0.472\n",
            "\n",
            "Epoch: 3\n",
            "learning rate:  0.05\n",
            "Train loss: 1.303 | Train acc: 0.530\n",
            "Val loss: 1.308 | Val acc: 0.528\n",
            "\n",
            "Epoch: 4\n",
            "learning rate:  0.05\n",
            "Train loss: 1.212 | Train acc: 0.567\n",
            "Val loss: 1.218 | Val acc: 0.567\n",
            "\n",
            "Epoch: 5\n",
            "learning rate:  0.05\n",
            "Train loss: 1.144 | Train acc: 0.593\n",
            "Val loss: 1.280 | Val acc: 0.548\n",
            "\n",
            "Epoch: 6\n",
            "learning rate:  0.05\n",
            "Train loss: 1.092 | Train acc: 0.612\n",
            "Val loss: 1.106 | Val acc: 0.604\n",
            "\n",
            "Epoch: 7\n",
            "learning rate:  0.05\n",
            "Train loss: 1.050 | Train acc: 0.624\n",
            "Val loss: 1.087 | Val acc: 0.616\n",
            "\n",
            "Epoch: 8\n",
            "learning rate:  0.05\n",
            "Train loss: 1.017 | Train acc: 0.641\n",
            "Val loss: 1.071 | Val acc: 0.623\n",
            "\n",
            "Epoch: 9\n",
            "learning rate:  0.05\n",
            "Train loss: 0.990 | Train acc: 0.650\n",
            "Val loss: 1.169 | Val acc: 0.598\n",
            "\n",
            "Epoch: 10\n",
            "learning rate:  0.05\n",
            "Train loss: 0.971 | Train acc: 0.657\n",
            "Val loss: 1.120 | Val acc: 0.610\n",
            "\n",
            "Epoch: 11\n",
            "learning rate:  0.05\n",
            "Train loss: 0.945 | Train acc: 0.667\n",
            "Val loss: 1.078 | Val acc: 0.622\n",
            "\n",
            "Epoch: 12\n",
            "learning rate:  0.05\n",
            "Train loss: 0.934 | Train acc: 0.670\n",
            "Val loss: 1.123 | Val acc: 0.618\n",
            "\n",
            "Epoch: 13\n",
            "learning rate:  0.05\n",
            "Train loss: 0.914 | Train acc: 0.676\n",
            "Val loss: 0.976 | Val acc: 0.653\n",
            "\n",
            "Epoch: 14\n",
            "learning rate:  0.05\n",
            "Train loss: 0.909 | Train acc: 0.682\n",
            "Val loss: 1.056 | Val acc: 0.622\n",
            "\n",
            "Epoch: 15\n",
            "learning rate:  0.05\n",
            "Train loss: 0.898 | Train acc: 0.685\n",
            "Val loss: 0.995 | Val acc: 0.651\n",
            "\n",
            "Epoch: 16\n",
            "learning rate:  0.05\n",
            "Train loss: 0.883 | Train acc: 0.691\n",
            "Val loss: 1.026 | Val acc: 0.640\n",
            "\n",
            "Epoch: 17\n",
            "learning rate:  0.05\n",
            "Train loss: 0.879 | Train acc: 0.690\n",
            "Val loss: 1.000 | Val acc: 0.651\n",
            "\n",
            "Epoch: 18\n",
            "learning rate:  0.05\n",
            "Train loss: 0.873 | Train acc: 0.692\n",
            "Val loss: 0.978 | Val acc: 0.658\n",
            "\n",
            "Epoch: 19\n",
            "learning rate:  0.05\n",
            "Train loss: 0.863 | Train acc: 0.694\n",
            "Val loss: 0.947 | Val acc: 0.670\n",
            "\n",
            "Epoch: 20\n",
            "learning rate:  0.05\n",
            "Train loss: 0.856 | Train acc: 0.700\n",
            "Val loss: 0.958 | Val acc: 0.667\n",
            "\n",
            "Epoch: 21\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.851 | Train acc: 0.702\n",
            "Val loss: 0.976 | Val acc: 0.659\n",
            "\n",
            "Epoch: 22\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.722 | Train acc: 0.746\n",
            "Val loss: 0.782 | Val acc: 0.727\n",
            "\n",
            "Epoch: 23\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.667 | Train acc: 0.765\n",
            "Val loss: 0.765 | Val acc: 0.731\n",
            "\n",
            "Epoch: 24\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.652 | Train acc: 0.772\n",
            "Val loss: 0.745 | Val acc: 0.739\n",
            "\n",
            "Epoch: 25\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.640 | Train acc: 0.775\n",
            "Val loss: 0.727 | Val acc: 0.747\n",
            "\n",
            "Epoch: 26\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.624 | Train acc: 0.780\n",
            "Val loss: 0.743 | Val acc: 0.742\n",
            "\n",
            "Epoch: 27\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.616 | Train acc: 0.782\n",
            "Val loss: 0.753 | Val acc: 0.737\n",
            "\n",
            "Epoch: 28\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.610 | Train acc: 0.785\n",
            "Val loss: 0.760 | Val acc: 0.740\n",
            "\n",
            "Epoch: 29\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.600 | Train acc: 0.789\n",
            "Val loss: 0.770 | Val acc: 0.733\n",
            "\n",
            "Epoch: 30\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.596 | Train acc: 0.788\n",
            "Val loss: 0.715 | Val acc: 0.754\n",
            "\n",
            "Epoch: 31\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.585 | Train acc: 0.794\n",
            "Val loss: 0.738 | Val acc: 0.741\n",
            "\n",
            "Epoch: 32\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.581 | Train acc: 0.797\n",
            "Val loss: 0.729 | Val acc: 0.752\n",
            "\n",
            "Epoch: 33\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.571 | Train acc: 0.798\n",
            "Val loss: 0.731 | Val acc: 0.745\n",
            "\n",
            "Epoch: 34\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.569 | Train acc: 0.800\n",
            "Val loss: 0.740 | Val acc: 0.747\n",
            "\n",
            "Epoch: 35\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.563 | Train acc: 0.802\n",
            "Val loss: 0.763 | Val acc: 0.739\n",
            "\n",
            "Epoch: 36\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.558 | Train acc: 0.802\n",
            "Val loss: 0.744 | Val acc: 0.744\n",
            "\n",
            "Epoch: 37\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.552 | Train acc: 0.805\n",
            "Val loss: 0.746 | Val acc: 0.739\n",
            "\n",
            "Epoch: 38\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.544 | Train acc: 0.808\n",
            "Val loss: 0.748 | Val acc: 0.744\n",
            "\n",
            "Epoch: 39\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.543 | Train acc: 0.808\n",
            "Val loss: 0.751 | Val acc: 0.742\n",
            "\n",
            "Epoch: 40\n",
            "learning rate:  0.005000000000000001\n",
            "Train loss: 0.541 | Train acc: 0.808\n",
            "Val loss: 0.749 | Val acc: 0.741\n",
            "\n",
            "Epoch: 41\n",
            "learning rate:  0.004000000000000001\n",
            "Train loss: 0.536 | Train acc: 0.808\n",
            "Val loss: 0.730 | Val acc: 0.747\n",
            "\n",
            "Epoch: 42\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-7e291b602f1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# forward + backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtrain_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mtrainloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtrainloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm3d\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \"\"\"\n\u001b[0;32m-> 2422\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m         return handle_torch_function(\n\u001b[1;32m   2424\u001b[0m             \u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot accuracy curve\n",
        "plt.figure(0)\n",
        "plt.plot(range(1,EPOCH+1,1), np.array(train_acc), 'r-', label= \"train accuracy\") \n",
        "plt.plot(range(1,EPOCH+1,1), np.array(val_acc), 'b-', label= \"val accuracy\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot loss curve\n",
        "plt.figure(1)\n",
        "plt.plot(range(1,EPOCH+1,1), np.array(train_loss), 'r-', label= \"train loss\") \n",
        "plt.plot(range(1,EPOCH+1,1), np.array(val_loss), 'b-', label= \"val loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g-QShVIgmicX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}